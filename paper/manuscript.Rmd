---
title: "Variation in gaze following across the life span: A process-level perspective"
shorttitle: "modeling variation in gaze following"
author: 
  
  - name          : "Julia Christin Prein"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "Max Planck Institute for Evolutionary Anthropology, Deutscher Platz 6, 04103 Leipzig, Germany"
    email         : "julia_prein@eva.mpg.de"
    role          :
      - Conceptualization
      - Methodology
      - Software
      - Investigation
      - Formal Analysis
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
      
  - name          : "Luke Maurits"
    affiliation   : "1"
    role          : 
      - Formal Analysis
      - Writing - Review & Editing
      
  - name          : "Annika Werwach"
    affiliation   : "3,4"
    role          :
      - Methodology
      - Investigation
      - Writing - Review & Editing  
      
  - name          : "Daniel B. M. Haun"
    affiliation   : "1,*"
    role          :
      - Supervision
      - Writing - Review & Editing
      
  - name          : "Manuel Bohn"
    affiliation   : "1,2,*"
    role          :
      - Conceptualization
      - Formal Analysis
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
    
affiliation:
  - id            : "1"
    institution   : "Department of Comparative Cultural Psychology, Max Planck Institute for Evolutionary Anthropology, Leipzig, Germany"
  - id            : "2"
    institution   : "Institute of Psychology, Leuphana University Lüneburg, Germany"
  - id            : "3"
    institution   : "Center for Lifespan Psychology, Max Planck Institute for Human Development, Berlin, Germany"
  - id            : "4"
    institution   : "Max Planck School of Cognition, Leipzig, Germany"
  - id            : "*"
    institution   : "Shared senior authorship" 
abstract: |
  Following eye gaze is fundamental for many social-cognitive abilities, for example, when judging what another agent can or cannot know. While the emergence of gaze following has been thoroughly studied on a group level, we know little about (a) the developmental trajectory beyond infancy and (b) the sources of individual differences. In Study 1, we examined gaze following across the lifespan (*N* = 471 3- to 80-year-olds; children from a mid-sized German city; international remotely tested adults). We found a steep performance improvement during preschool years, in which children became more precise in locating the attentional focus of an agent. Precision levels then stayed comparably stable throughout adulthood with a minor decline toward old age. In Study 2, we formalized the process of gaze following in a computational cognitive model that allowed us to conceptualize individual differences in a psychologically meaningful way (*N* = 60 3- to 5-year-olds, 50 adults). According to our model, participants estimate pupil angles with varying levels of precision based on observing the pupil location within the agent's eyes. In Study 3, we empirically tested how gaze following relates to vector following in non-social settings and perspective-taking abilities (*N* = 102 4- to 5-year-olds). We found that gaze following is associated with both of these abilities but less so with other Theory of Mind tasks. This work illustrates how the combination of reliable measurement instruments and formal theoretical models allows us to explore the in(ter)dependence of core social-cognitive processes in greater detail.
keywords          : "social-cognitive development, theory of mind, gaze following, individual differences, cognitive modeling, lifespan"
wordcount         : "10469"
floatsintext      : yes
figurelist        : yes
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : yes 
draft             : no
classoption       : "man"

header-includes:
  - \usepackage{setspace}
  - \captionsetup[figure]{font={stretch=1}}
  - |
    \makeatletter
    \renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-1em}%
      {\normalfont\normalsize\bfseries\typesectitle}}
    
    \renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{1em}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-\z@\relax}%
      {\normalfont\normalsize\bfseries\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
    \makeatother

csl               : "`r system.file('rmd', 'apa7.csl', package = 'papaja')`"
documentclass     : "apa7"
output            : papaja::apa6_word

editor_options    : 
  markdown: 
    wrap: sentence
bibliography      : "../../references.bib"
---

```{r setup, include = FALSE}
library("tidyverse")
library("papaja")
library("kableExtra")
library("brms")
library("janitor")

theme_set(theme_classic())
```

```{r analysis_preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# Variation in gaze following across the life span: A process-level perspective

**Authors:** Julia Christin Prein^1^, Luke Maurits^1^, Annika Werwach^1,3,4^, Daniel B. M. Haun^1,\*^, Manuel Bohn^1,2,\*^

**Affiliations:** ^1^ Department of Comparative Cultural Psychology, Max Planck Institute for Evolutionary Anthropology, Leipzig, Germany.
^2^ Institute of Psychology, Leuphana University Lüneburg, Germany.
^3^ Center for Lifespan Psychology, Max Planck Institute for Human Development, Berlin, Germany.
^4^ Max Planck School of Cognition, Leipzig, Germany.
^\*^ shared senior authorship

**ORCiD**: *Julia Christin Prein* <https://orcid.org/0000-0002-3154-6167>

**Conflicts of interest:** The authors declare that they have no conflict of interest.

**Data availability statement:** The gaze following task (<https://ccp-odc.eva.mpg.de/tango-demo/>) is open source (<https://github.com/ccp-eva/tango-demo>). The data sets generated during and/or analyzed during the current study are available in the following repository (<https://github.com/ccp-eva/gazecues-modeling>). All experiments and analyses were pre-registered prior to data collection (<https://osf.io/zjhsc/>).

**Acknowledgements:** We thank Jana Jurkat for her help with data collection and participant recruitment. We would also like to thank Steven Kalinke for his technical programming support. We thank all the children, caregivers, and adults who participated in the study.

**Funding:** This study was funded by the Max Planck Society for the Advancement of Science, a noncommercial, publicly financed scientific organization (no grant number). Manuel Bohn was supported by a Jacobs Foundation Research Fellowship (grant no. 2022-1484-00).

**Ethical statement:**  The study obtained ethical clearance by the MPG Ethics commission Munich, Germany, falling under an umbrella ethics application (Appl. No. 2021_45). Informed consent was obtained from all individual participants or their legal guardians. The research adhered to the legal requirements of psychological research with children in Germany. 

\newpage

# Research highlights (to be placed before the abstract)

-	Gaze following develops beyond infancy. Highest precision levels in localizing attentional foci are reached in young adulthood with a slight decrease towards old age. 
-	We present a computational model that describes gaze following as a process of estimating pupil angles and the corresponding gaze vectors. 
- The model explains individual differences and recovers signature patterns in the data. To estimate the relation between gaze- and vector following, we designed a non-social vector following task. 
-	We found substantial correlations between gaze following and vector following, as well as Level 2 perspective-taking. Other Theory of Mind tasks did not correlate. 

# Introduction
Following the gaze of others is valuable for extracting information from the environment. It guides us to "informational hotspots" [@meltzoff2010social, p.1] and can be used to identify internal states such as intentions or emotions [@corkum1998origins; @pfeiffer2013gaze]. As one of the most fundamental social-cognitive abilities, gaze following is an integral part of almost every form of social interaction, including communication, collaboration, cultural and social learning [@emery2000eyes; @rakoczy2022foundations; @frith2012mechanisms; @tomasello2003makes; @bohn2019pervasive; @moore2008development; @hessels2020how], and has been extensively studied in infancy [for review, see @delbianco2019developmental]. In the most commonly used paradigm [e.g., @astor2020social; @gredeback2010development; @byers-heinlein2021development; @ishikawa2022physiological], the experimenter looks directly at the infant before shifting their head and eyes to one of two objects. Infants’ looking times to the target or the proportion of choosing the target over the distractor are measured. Research in this tradition finds that infants as young as three to four months can follow the gaze of another agent [@delbianco2019developmental; @dentremont2000perceptual; @dentremont1997demonstration; @astor2021gaze]. 

Previous research has shown a refinement of gaze following abilities in a child's first and second year of life [e.g., @astor2021gaze; @butterworth1991minds; @brooks2002importance]. At the end of their first year of life, infants can follow gaze to locations outside their current visual field and move themselves to gain proper perceptual access [@moll200412; @deak2000effects; @butterworth1991minds; @corkum1995development]. However, we do not know much about the developmental progression beyond these qualitative milestones. One possibility is that the ability to follow gaze does not improve beyond infancy. Yet, most, if not all, cognitive abilities continue to develop throughout childhood [e.g., @gathercole2004structure; @gredeback2010development]. It seems likely that children fine-tune their gaze following as they get older - presumably while using them in social interactions. To capture the development in gaze following beyond infancy, Study 1 included participants from preschool to old age. 

Up until today, only a handful of gaze following studies differentiate between manipulating head and eye movement. @michel2021effects found that gaze following in four-month-olds was likely driven by other's head- instead of eye movements. @corkum1995development, @lempers1979young, and @lempers1977development suggest that infants, at least until 19 months, struggle when eye and head direction diverge. From farther distance, body or face orientation can act as more salient cues to determine another's area of attention. However, eye direction indicates a more precise location of focus [@emery2000eyes; @stiefelhagen2002head; however, see @loomis2008psychophysics for peripheral vision], and allows to anticipate likely future actions [@zohary2022gaze; @friesen2011gaze]. The three studies included in this work, therefore, focused on subtle gaze cues and isolated eye movement alone.

Group-level analyses of gaze following abilities (e.g., average age at which children as a group reach an above-chance performance) may mask individual differences between children. Measuring individual differences in basic aspects of social cognition is important to understand the underlying processes and to quantify the impact of environmental influences and other cognitive abilities [@birch2017perspectives; @delbianco2019developmental]. Across the three studies, we measured gaze following continuously by using a task that is designed to capture individual-level variation [@prein2023tango]: the TANGO (Task for Assessing iNdividual differences in Gaze understanding - Open) avoids floor and ceiling effects in children and adults and is thus particularly suited to examine how gaze following changes with age. 

A promising approach to interpreting individual differences in cognitive abilities is computational cognitive modeling. Existing computational models have described gaze following via reinforcement learning [@ishikawa2020learning], as a consequence of goal interference and mapping self-experience onto other agents [@friesen2011gaze] or an interplay of object distances/saliencies and head poses [@lau2004learning; @jasso2006using; @recasens2015they]. As such, these models focus on the motivation behind gaze following or on situations in which the context (e.g., head orientation, surrounding objects) offers cues to the gaze direction. Our goal, however, was to formulate a theory that models how people estimate gaze direction based on the eyes alone (i.e., “literal” gaze following) when no target objects are present [^1] and the other’s head is frontally oriented. 

[^1]: As @jasso2006using put it: “There is a general agreement that tests of gaze following in the absence of targets are more stringent than with targets, because that eliminates the possibility that infants are simply following the target’s saliency” (p. 2). 

To our knowledge, there are three views that focus on the eyes alone that conceptualize gaze as (1) a beam, (2) a cone, or (3) a line (alternatively called a vector, ray, or line-of-sight). @guterstam2019implicit proposed the idea of gaze as a force-carrying beam. This theory, however, focuses on how people's implicit assumptions about the physical properties of an object changes when someone looks at it. The idea of gaze as a cone is mostly concerned with the question of how people determine whether someone else looks at them [@horstmann2021examining; @gamer2007you]. The conception most relevant to the present study sees eye gaze as a line: @yaniv1990heuristics proposed that children extrapolate an imaginary trajectory between the agent and the object to identify the focus of attention (similar to “geometrical” gaze following; [@butterworth1991minds]). Anecdotal evidence was already reported by @walker1977perspective, who observed two children pointing their fingers into the air, drawing a line between an agent and an object, and saying, “He sees that” (p. 354). @michelon2006two found that response time in Level 1 visual perspective-taking tasks depends on the distance between the agent and the object (i.e., the length of the line-of-sight). Some researchers additionally highlight iris eccentricity, that is, the ratio of the visible sclera on each side of the pupil [@anstis1969perception; @todorovic2006geometrical; @symons2004you]. @todorovic2006geometrical defined gaze direction as “the vector positioned along the visual axis, pointing from the fovea of the looker through the center of the pupil to the gazed-at spot” (p. 3550). @symons2004you furthermore reasoned that “the perceiver must use the asymmetrical configuration of the dark-white contrast of another individual’s eyes, and trace along two invisible sight-lines to their convergent point, that is, the third part of the triad (e.g., an object or a person)” (p. 452). Based on their finding that adults’ gaze direction sensitivity decreases when only one eye is shown, @symons2004you conclude that information from both eyes must be integrated. 

While the previously mentioned conceptualizations focus on the direction of eye gaze, they (A) cannot explain how people differ in their abilities to precisely estimate gaze direction, and (B) are not clearly expressed as formal, mathematical models with explicit assumptions and testable predictions. In the words of [@gamer2007you]: “Given the social relevance of determining gaze direction, the psychophysics of gaze is underdeveloped” (p. 705).  

Here, we propose a cognitive model of gaze following, which builds upon the notion of eye gaze as line-of-sight tracing and extends this by explicitly modeling individual differences. Our gaze model assumes participants infer the locus of someone’s attention to be where two estimated gaze vectors meet. Each of these gaze vectors results from connecting the center of the agent’s eyeball and the center of the pupil. Because the center of the eyeball is not directly observable, vector estimation happens with a degree of uncertainty. Development of gaze following corresponds to a decrease in uncertainty. Individual differences correspond to systematic differences in uncertainty.

By focusing on individual differences, we can further address the relationship between gaze following and other cognitive abilities. A longstanding question has been whether gaze following is related to Theory of Mind (ToM) [e.g., @brooks2015connecting]. @moll2011perspectivetaking have suggested that joint attention (including gaze following) might be seen as “Level 0 perspective-taking”, which provides the foundation for later-emerging, more complex perspective-taking abilities. On the other hand, an alignment of infants’ visual attention to another’s gaze does not necessarily indicate understanding the intentions of the agent [@aslin2007look]. Infants could simply align their orientation without processing what exactly the other is seeing [@butterworth1991minds]. In fact, one might question if such an alignment reflects an understanding of visual perspectives at all because the “target” or “object of representation” is not necessarily specified [@perner2003perspective, p. 358]. Consequently, @astor2022gaze have listed the relationship between gaze following and perspective-taking as one of their five big open questions in gaze following research. Therefore, in Study 3, we assessed how gaze following relates to ToM abilities, especially visual perspective-taking.

Taken together, the present study had three main goals: first, we studied the development of gaze following beyond infancy (Study 1). Instead of capturing the youngest age at which children follow gaze, we examined how this ability changes with age. Our second goal was to provide a process-level theory of gaze following – and, most importantly, individual differences therein. We proposed a computational cognitive model, which formalized gaze following as a form of vector following, and tested whether our model explained empirical data (Study 2). Third, we examined which (social-)cognitive components comprise gaze following (Study 3). Based on our model, we predicted that gaze following should be related to non-social vector following. Additionally, we assessed the link between gaze following and ToM measures, with a particular focus on visual perspective-taking. 

# Study 1: Gaze following across the lifespan

The study was pre-registered prior to data collection: <https://osf.io/snju6> (child sample) and <https://osf.io/6yjz3> (adult sample). The study obtained ethical clearance by the MPG Ethics commission in Munich, Germany, falling under an umbrella ethics application (Appl. No. 2021_45). Data was collected between May 2021 and April 2023.

```{r lifespan_sample, include = T, out.width = "100%"}
lifespan_sample <- readRDS("../saves/lifespan_sample.rds")
```

## Participants

We collected data online from 3- to 80- year-olds (see Supplements for further details). The child sample consisted of `r sum(lifespan_sample$n_total[lifespan_sample$age_group < 18])` participants and was recruited via an internal database of families in Leipzig, Germany, who volunteered to participate in child development studies. Participants came from ethnically homogeneous, mixed socioeconomic backgrounds with mid to high parental education levels. They lived in an industrialized, urban Central-European context in a mid-size German city (approx. 600,000 inhabitants; median individual monthly net income approx. 1,600€ as of 2021). Most were raised monolingually in a nuclear two-generational family setting. Information on demographics and socioeconomic status was not formally recorded on a participant level.

Adults were recruited via *Prolific* [@palan2018prolific]. *Prolific* is an online participant recruitment tool from the University of Oxford with predominantly European and US-American subjects. Participants consisted of `r sum(lifespan_sample$n_total[lifespan_sample$age_group >= 20])` English-speaking adults who reported to have normal or corrected-to-normal vision. For completing the study, subjects were paid above the fixed minimum wage (~£10.00/hour). 

## Materials

We used the continuous version of the TANGO [@prein2023tango]. The task was presented as a web application (demo [https://ccp-odc.eva.mpg.de/tango-demo/](https://ccp-odc.eva.mpg.de/tango-demo/.); source code <https://github.com/ccp-eva/tango-demo>). The TANGO showed satisfactory internal consistency and retest reliability (*Pearson's r* from .7 to .8; @prein2023tango) and no floor or ceiling effects for children and adults.

## Procedure

Children and teenagers received a personalized link to the study website. Caregivers were asked to provide technical support, while explicitly being reminded not to help in responding. Webcam videos were recorded whenever consented and technically feasible in order to monitor whether children and teenagers responded on their own. Adults completed the online study unsupervised.

Each trial presented an agent standing in a window, watching a balloon (*i.e.*, target) falling to the ground (see Figure \@ref(fig:fig4)A; however, Study 1 presented animal agents). The target fell behind a hedge while the agent's gaze followed the target's trajectory. In test trials, a hedge covered the target's position. Participants were asked to touch or click where they estimated the target to be based on the agent's gaze. Four familiarization trials ensured participants understood the task and felt comfortable with the response format. Then, 15 test trials followed. Completing 19 trials took 5-10 minutes.

We measured imprecision, defined as the absolute difference between the target center and the x coordinate of the participant's click. The screen width was divided into ten bins. Within each bin, exact target coordinates were randomly generated. Each target bin, agent, and target color occurred equally often and did not appear in more than two consecutive trials.

## Analysis

We ran all analyses in `r R.version$version.string` [@rcoreteam2022language]. Regression models were fit as Bayesian generalized linear mixed models (GLMMs) with default priors using the function `brm` from the package `brms` [@burkner2017brms; @burkner2018advanced].

We fit GLMMs that make different assumptions about the developmental trajectory, modeling the relationship between age and performance as linear, quadratic, or cubic. In addition, we fit a Gaussian Process model [@burkner2017brms], which assumes a smooth relationship but avoids enforcing a particular shape. Per individual, imprecision was aggregated across trials and modeled as a `lognormal` distribution.[^2] The unit of imprecision was counted in target widths, i.e., an imprecision of 1 meant clicking one balloon width to the left or right of the true target center. We inspected the posterior distributions (mean and 95% Credible Interval (CrI)) for the age estimates and compared models via model weights and the difference in expected log pointwise predictive density (ELPD) estimated using leave-one-out cross-validation (LOO) [@vehtari2017practicala].

[^2]: Originally, we fit our models on a trial-by-trial basis with the following structure: `performance ~ age + symmetricPosition + trialNr + (1 + symmetricPosition + trialNr | subjID)`. However, the Gaussian Process model was computationally heavy. Thus, we simplified the model structure, aggregated data on a subject level, and included only age as an effect. See Supplements for a comparison between the original and the here-reported model structures. The model predictions did not differ notably.

To obtain a concise but principled characterization of the developmental trajectory, we additionally performed a Bayesian change point analysis, using the package `RBeast` [@zhao2019detecting]. We sought the most likely change points in our data, assuming a constant mean (i.e., a flat line, zero-degree polynomial) within each segment. To avoid "overreactions" to outlying data points, we constrained the model to have minimally 10 data points between consecutive change points (= half of the data points collected per adult decade). We inspected the posterior probability of different numbers of change points and the locations of these change points (mean and 95% CrI).[^3]

[^3]: In a supplementary analysis, we varied the parameters of our change point analysis and modified the number of allowed change points, the minimum number of data points between change points, and the polynomial order. When we allowed more explorative room, the models became more sensitive and added more fine-grained change points. The exact location of the change points varied slightly. However, the overall interpretation stayed the same, fitting our initial visual inspection: while early childhood was characterized by much change, adults showed a relatively stable level of imprecision, with a minor decay toward elderly adulthood. See Supplements for further detail.

## Results

(ref:figlab1) **Developmental trajectory of gaze following across the lifespan**. Grey dots show the mean level of imprecision (i.e., absolute distance between the target's center and the participant's click) for each subject averaged across trials. The unit of imprecision is counted in target width, i.e., a participant with imprecision of 1 clicked on average one target width to the left or right of the true target center. Blue lines show 100 draws from the expectation of the posterior predictive distribution of the Gaussian Process model, with its mean predicted developmental trajectory as a solid black line. Vertical, black, dashed lines show the locations of the changes with the highest posterior probability according to our Bayesian change point analysis. 

```{r fig1, include = T, out.width = "100%", fig.align = "center", fig.cap = "(ref:figlab1)"}
knitr::include_graphics(c("../figures/lifespan_plot.png"))
```

```{r lifespan_results, include=FALSE}
lifespan_variation <- readRDS("../saves/lifespan_variation_all.rds")
lifespan_mcomparison <- readRDS("../saves/lifespan_mcomparison.rds") %>% mutate_if(is.numeric, round, 2)
lifespan_mgaussianprocess <- readRDS("../saves/lifespan_mgaussianprocess.rds")
lifespan_beast <- readRDS("../saves/lifespan_ibeast.rds")
lifespan_cps <- readRDS("../saves/lifespan_ibeast_cps.rds") %>% round(2) %>% arrange(cp)
lifespan_cps_descr <- readRDS("../saves/lifespan_cps_descr.rds")

lifespan_gp <- summary(lifespan_mgaussianprocess)$gp %>% 
  rownames_to_column("param") %>% 
  clean_names()
```

High levels of variation pointed to substantial individual differences in all age groups (overall imprecision mean = `r lifespan_variation$imprecision_mean`, sd = `r lifespan_variation$imprecision_sd`, range = [`r lifespan_variation$imprecision_min` - `r lifespan_variation$imprecision_max`]). We found substantial evidence for a non-linear development in gaze following across the lifespan (see Figure \@ref(fig:fig1)). The Gaussian process model was clearly preferred over the polynomial models due to the highest predictive accuracy according to the LOO ELPD estimates: elpd_diff between Gaussian process and cubic model = `r lifespan_mcomparison$elpd_diff[lifespan_mcomparison$model == "mcubic"]` (SE = `r lifespan_mcomparison$se_diff[lifespan_mcomparison$model == "mcubic"]`); elpd_diff between Gaussian process and quadratic model = `r lifespan_mcomparison$elpd_diff[lifespan_mcomparison$model == "mquadratic"]` (SE = `r lifespan_mcomparison$se_diff[lifespan_mcomparison$model == "mquadratic"]`); elpd_diff between Gaussian process and linear model = `r lifespan_mcomparison$elpd_diff[lifespan_mcomparison$model == "mlinear"]` (SE = `r lifespan_mcomparison$se_diff[lifespan_mcomparison$model == "mlinear"]`); all in favor of the Gaussian process model. Moreover, the Gaussian Process model showed the greatest model weight (approximating `r lifespan_mcomparison$modelweight[lifespan_mcomparison$model == "mgaussianprocess"]`). For the imprecision in gaze following, the standard deviation of the Gaussian process (SD = `r lifespan_gp$estimate[lifespan_gp$param == "sdgp(gpage_centered)"]`, 95% CrI [`r lifespan_gp$l_95_percent_ci[lifespan_gp$param == "sdgp(gpage_centered)"]`; `r lifespan_gp$u_95_percent_ci[lifespan_gp$param == "sdgp(gpage_centered)"]`]) indicated nonlinearity.

The Bayesian change point analysis revealed `r lifespan_beast$trend$ncp_mode` major shifts in gaze following during the lifespan (MAP estimate with `r lifespan_beast$trend$ncpPr[lifespan_beast$trend$ncp_mode + 1] * 100 %>% round(2)`% probability). The change points occurred at `r lifespan_cps$cp[1]` years (95% CrI [`r lifespan_cps$lowerCrI[1]`; `r lifespan_cps$upperCrI[1]`], mean imprecision until change point = `r lifespan_cps_descr[1,]$mean`, SD = `r lifespan_cps_descr[1,]$sd`); `r lifespan_cps$cp[2]` years (95% CrI [`r lifespan_cps$lowerCrI[2]`; `r lifespan_cps$upperCrI[2]`], mean = `r lifespan_cps_descr[2,]$mean`, SD = `r lifespan_cps_descr[2,]$sd`); `r lifespan_cps$cp[3]` years (95% CrI [`r lifespan_cps$lowerCrI[3]`; `r lifespan_cps$upperCrI[3]`], mean = `r lifespan_cps_descr[3,]$mean`, SD = `r lifespan_cps_descr[3,]$sd`); `r lifespan_cps$cp[4]` years (95% CrI [`r lifespan_cps$lowerCrI[4]`; `r lifespan_cps$upperCrI[4]`], mean = `r lifespan_cps_descr[4,]$mean`, SD = `r lifespan_cps_descr[4,]$sd`); `r lifespan_cps$cp[5]` years (95% CrI [`r lifespan_cps$lowerCrI[5]`; `r lifespan_cps$upperCrI[5]`], mean = `r lifespan_cps_descr[5,]$mean`, SD = `r lifespan_cps_descr[5,]$sd`); and `r lifespan_cps$cp[6]` years (95% CrI [`r lifespan_cps$lowerCrI[6]`; `r lifespan_cps$upperCrI[6]`], mean = `r lifespan_cps_descr[6,]$mean`, SD = `r lifespan_cps_descr[6,]$sd`). In short: we found a rapid initial improvement in gaze following in early childhood, followed by a long period of minor, very slow change with slightly increasing levels of imprecision toward old age.

## Discussion

We investigated the shape of change in gaze following across the lifespan and found a non-linear developmental trajectory, in which young children quickly enhanced their level of proficiency. Performance peaked around early adulthood, while there was a minor decay in later adulthood. These results support the idea that humans fine-tune their existing gaze following ability after the first emergence in infancy. Furthermore, we observed substantial individual differences in all age groups. While variation was highest in the three- and four-year-olds, it remained relatively stable across the lifespan.

Previous studies found that already four-month-olds demonstrate basic gaze following abilities [@delbianco2019developmental]. Since we measured an active location choice on a touchscreen, we could not collect data from infants. In our sample, three-year-olds were still rather imprecise in their gaze following ability (average imprecision was approx. two target widths). How can we explain this divergence? First, we used subtle eye movements as cues. Many existing studies let the agents move eye and head in parallel [@behne2005oneyearolds; @povinelli1997exploitation], establishing a confound with the more salient head movement. Relying exclusively on eye movements might be more difficult for children than presenting them with a combined eye and head orientation [@carpenter1998social]. @silverstein2021infants used a similar manipulation of gaze cues without head rotation and found that 6- to 18-month-olds were around or just above chance for gaze following. The authors argue that infants might fixate on another's face most of the time, while eye movement alone might not be strong enough to guide their attention. Furthermore, our study required participants to (1) precisely follow an agent's gaze, (2) interpret this as a cue, and (3) use the cue to guide their own behavior. It is conceivable that three-year-olds followed the agent's gaze but did not translate this into precise, active behavior. @moll2013primacy argue that social forms of perspective-taking evolve prior to visual perspective-taking, which only emerges within the third year of life. Young children might simply not be interested in a differential, spatial representation of the surrounding objects. Taken together, this might explain why our younger participants located the agent's gaze rather imprecisely.

Regarding our sample of elderly adults, we expect a sampling bias [@bethlehem2010selection; @gosling2004should; @remillard2014systematic]. First, certainly not all older people have a high-speed internet connection or are knowledgeable in its use. Second, the elderly adults participating in *Prolific* studies might show greater cognitive flexibility compared to their offline counterparts. Therefore, a representative sample may show a greater age decline in gaze following compared to our reported sample. In addition, older people might be more likely to suffer from visual impairments. Even though we filtered participants to only include normal- to correct-to-normal vision, we cannot guarantee that our participants showed no symptoms of reduced vision.

# Study 2: Computational cognitive model

Our lifespan study showed that gaze following develops throughout childhood, and variation between individuals appears in all age groups. The TANGO has previously been shown to reliably capture inter-individual differences in gaze following [@prein2023tango]. The variation between participants was thus likely genuine and not due to random noise. In Study 2, we aimed to understand the developmental change and individual differences on a process level. We present a theory of gaze following that explains how participants process the available gaze information and trace a line-of-sight to identify the agent's focus. We formalized this inference process in a computational cognitive model that replicates a schematic representation of how participants make inferences in the task’s context (i.e., a model of the task and not the data).

The study design and procedure obtained ethical clearance in the same way as Study 1. The study and the model were pre-registered prior to data collection: <https://osf.io/r3bhn>. Data were collected between May and August 2021.

## Computational model

Our model quantifies a participant's cognitive ability to follow gaze by inverting a probabilistic process that generates the participant's clicks from observing the eyes of the agent. It is formally defined as:

\begin{equation}
    P(\theta | x_c, \alpha_l, \alpha_r) \propto P(x_c | \alpha_l, \alpha_r, \theta)P(\theta)
\end{equation}

where $\theta$ is an individual's cognitive ability to locate the focus of the agent's attention, $x_c$ is the coordinate the participant clicked, and $\alpha_l$ and $\alpha_r$ are the pupil angles for the left and right eye, respectively. The pupil angle $\alpha$ is defined as the angle between a line connecting the center of the eye to the pupil and a line extended vertically downward from the center of the eye (see Figure \@ref(fig:fig2)A)[^4]. Please note that in our case, the center of the pupil is simultaneously the center of the iris (see @anstis2018role for the influence of moving irises, pupils, and corneal reflexes). 

[^4]: This model mirrors the logic of the TANGO programming code. In the online experiment, we read out the center point coordinates of the target and the agent's eyeball (i.e., the SVG coordinates), and then calculated a line between these two points: this was our gaze vector (acting in the functionally same way as a pupil angle). Knowing the eyeball radius, we calculated the point of intersection at which the gaze vector met the eyeball boundary. Finally, the agent's pupil moved from the center of the eyeball along the gaze vector to the intersection point. This way, the agent was animated to "look at" the target. In the gaze model, we assumed participants go through these steps in reverse order.

Based on our verbal task instructions, we assumed that participants (1) expected the agent's looks to be directed at the target, and (2) to click on the coordinate they estimated the agent to look at. Consequently, we did not assume that participants' clicks were noisy in any way but that they clicked on the screen location where they genuinely thought the target was (and that the agent was looking at). 

The true eye angles ($\alpha_l$ and $\alpha_r$) cannot be directly observed and have to be estimated based on the position of the pupils within the eyes, resulting in approximate values ($\hat{\alpha_l}$ and $\hat{\alpha_r}$). We presumed this estimation to be a noisy process. Thus, we conceptualized the development of the cognitive ability to follow gaze as a reduction of noise in the estimates (i.e., an increased certainty about the pupil angles).

Any clicked value of $x_c$ implied a "matched pair" of the estimated pupil angles $\hat{\alpha_l}$ and $\hat{\alpha_r}$, with the property that lines extended along those two angles met at the precise location of the target. As a consequence, we can rewrite the likelihood function of the model above:

\begin{equation}
P(x_c | \alpha_l, \alpha_r, \theta) \propto P(\hat{\alpha_l}, \hat{\alpha_r} | \alpha_l, \alpha_r, \theta) P(x_c)
\end{equation}

$P(x_c)$ is a prior over potential target locations, which we assumed to be skewed towards the screen center: We anticipated that participants have an a priori expectation that the target will land close to the middle, because the target was last visible in the screen center before disappearing behind the hedge and because the agent was located centrally on the screen. We estimated the strength of this center bias (i.e., the standard deviation of a Normal distribution around the screen center) based on the data: $P(x_c) \sim \mathcal{N}(960, \sigma^p)$. 

The width of this distribution is defined by $\sigma^p$. For children, we assumed that the center bias changed with age and estimated $\sigma^p$ via a linear regression as a function of the child's age ($age_i$): $\sigma^p = \beta_0^{\sigma^p} + age_i \cdot \beta_1^{\sigma^p}$. Therefore, the participant-specific distribution for $P(x_c)$ was constrained by the performance in the TANGO and the child's age. For the adults, $\sigma^p$ was not age-specific.

The main inferential task for the participant lay in estimating the pupil angles, i.e., sampling from the first term of the right-hand side equation above, $P(\hat{\alpha_l}, \hat{\alpha_r} | \alpha_l, \alpha_r, \theta)$. For this, we assumed that the pair of estimated pupil angles were sampled from a probability distribution which is the product of two Normal distributions of equal variance, $\sigma_v$, centered on the true pupil angles:

\begin{equation}
P(\hat{\alpha_l}, \hat{\alpha_r} | \alpha_l, \alpha_r, \theta) \propto \phi(\hat{\alpha}_l ; \alpha_l, \sigma_v)\phi(\hat{\alpha}_r ; \alpha_r, \sigma_v),
\end{equation}

As $\sigma_v$ determined the level of accuracy with which participants estimated the pupil angles, it is the component of the model that defines $\theta$. When $\sigma_v$ is very small (i.e., the distribution around the pupil angle is narrow), clicks far away from the target are unlikely, as these would require estimated pupil angles very different from the true pupil angles.\ When $\sigma_v$ is very large (i.e., the distribution around the pupil angle is wide), almost any pupil angles may be sampled, corresponding to a roughly uniform distribution over click coordinates. We expected $\sigma_v$ to vary between individuals. Consequently, individuals differed in the level of precision with which they can locate the target based on observing the agent's eyes.

The shape of the $P(x_c | \alpha_l, \alpha_r, \theta)$ distribution leads to a testable group-level prediction. As the pupil location varies, a fixed amount of uncertainty around the pupil angle corresponds to a varying degree of uncertainty in the estimated target location (see Figure \@ref(fig:fig2)B & C). When the agent directs their gaze toward the very left or right side, the distribution around the target location from which participants sample is comparatively wider than when the agent gazes centrally to the ground. For illustrative purposes, imagine a similar phenomenon: pointing a torch light to a flat surface on the ground. When one points the light cone directly at the surface, the light beam is concentrated in a clearly defined, small, symmetric area. When one points the light cone further away from oneself (shining at an angle), the light from one half of the cone must travel further to reach the surface than the light from the other half, resulting in an asymmetric light pattern. As the angle increases, the light is spread over a wider area, and the surface is illuminated less evenly. Consequently, for the same $\sigma_v$, the further out a target coordinate lies, the wider and less symmetric the distribution. This increases both the variance and the bias in a participant's estimate of the agent's attentional focus, resulting in a decreased performance in the task. As $\sigma_v$ decreases and the cone narrows, the extent to which performance varies at different angles decreases. 

Our gaze model consequently predicted that TANGO trials vary in difficulty (see Figure \@ref(fig:fig2)B and C): participants should be more imprecise in locating the target the further out it lands, resulting in a U-shaped pattern[^5]. If our data matched the pattern of this model prediction, this could act as evidence for the gaze model. Therefore, our gaze model provides a quantitative theory of gaze following. In the following, we tested these predictions in children and adults. 

[^5]: In our screen-based study, this effect should decrease again towards the most outward sides. Since the computer screen has a natural border, trials in which the target lands furthest out to the left/right become slightly easier again. In these cases, the uncertainty about the pupil angle faces practically only the inner side (facing the center) of the screen, since the natural border of the screen limits where participants can click. In another adult sample with more trials, we could recover this pattern. For further elaboration, see Supplements.

(ref:figlab2) **Gaze model** (A) Visualization of the gaze model (simplified, for one eye). Participants are assumed to observe the pupil location and estimate the center of the agent's eye. Connecting these two point estimates as a line yields the unique vector that extends from the center of the agent's eyeball through the center of the pupil to the attentional focal point (line-of-sight). The angle between this vector and a line pointing vertically to the ground (black dashed line) is the pupil angle ($\alpha$). Participants are assumed to sample (grey lines) from Normal distributions (blue line) centered around the true pupil angle. The variance of the Normal distribution ($\sigma_v$) is expected to vary between participants. (B & C) Geometrical features of the gaze model. As the pupil angle varies, a fixed amount of uncertainty in the angle corresponds to a varying degree of uncertainty in the estimated target location. The distribution around the target location from which participants sample is wider when the agent gazes toward the side than when she gazes centrally. The blue line on the ground shows the added level of uncertainty in the estimated target position for the target location further outward (C). 

```{r fig2, include = T, out.width = "100%", fig.align = "center", fig.cap = "(ref:figlab2)"}
knitr::include_graphics("../figures/gazemodel.png")
```

## Participants

```{r gazemodel_sample}
gazemodel_sample <- readRDS("../saves/gazemodel_sample.rds")
```

The sample consisted of `r sum(gazemodel_sample$n_total[gazemodel_sample$age_group < 6])` children, including `r gazemodel_sample$n_total[gazemodel_sample$age_group == 3]` three-year-olds (mean age = `r gazemodel_sample$age_mean[gazemodel_sample$age_group == 3]` years, SD = `r gazemodel_sample$age_sd[gazemodel_sample$age_group == 3]`, range = `r gazemodel_sample$age_min[gazemodel_sample$age_group == 3]` - `r gazemodel_sample$age_max[gazemodel_sample$age_group == 3]`, `r gazemodel_sample$n_females[gazemodel_sample$age_group == 3]` girls), `r gazemodel_sample$n_total[gazemodel_sample$age_group == 4]` four-year-olds (mean age = `r gazemodel_sample$age_mean[gazemodel_sample$age_group == 4]` years, SD = `r gazemodel_sample$age_sd[gazemodel_sample$age_group == 4]`, range = `r gazemodel_sample$age_min[gazemodel_sample$age_group == 4]` - `r gazemodel_sample$age_max[gazemodel_sample$age_group == 4]`, `r gazemodel_sample$n_females[gazemodel_sample$age_group == 4]` girls), `r gazemodel_sample$n_total[gazemodel_sample$age_group == 5]` five-year-olds (mean age = `r gazemodel_sample$age_mean[gazemodel_sample$age_group == 5]` years, SD = `r gazemodel_sample$age_sd[gazemodel_sample$age_group == 5]`, range = `r gazemodel_sample$age_min[gazemodel_sample$age_group == 5]` - `r gazemodel_sample$age_max[gazemodel_sample$age_group == 5]`, `r gazemodel_sample$n_females[gazemodel_sample$age_group == 5]` girls). Children were recruited via an internal database, where each parent previously consented to child development studies, and data was collected in kindergartens in Leipzig, Germany. 

In addition, we included `r gazemodel_sample$n_total[gazemodel_sample$age_group == 18]` adults from Study 1 (mean age = `r gazemodel_sample$age_mean[gazemodel_sample$age_group == 18]` years, SD = `r gazemodel_sample$age_sd[gazemodel_sample$age_group == 18]`, range = `r gazemodel_sample$age_min[gazemodel_sample$age_group == 18]` - `r gazemodel_sample$age_max[gazemodel_sample$age_group == 18]`, `r gazemodel_sample$n_females[gazemodel_sample$age_group == 18]` female). Since developmental change was minimal in our adult sample (see Study 1) and the cognitive models were computationally heavy, we decided to only include the first 50 adults who had completed the study.

## Procedure

We applied the same procedure as in Study 1. Children were tested in a quiet room in their kindergarten, while an experimenter guided the child through the study on a tablet. Adults participated online.

## Analysis

We quantified how well our gaze model explained the gaze following process in two ways. First, we aggregated the model predictions and data for each target bin and age group (3-, 4-, 5-years-olds, adults), and computed correlation to quantify how well the model was able to recover the data. Second, we compared the predictions of our gaze model to two simple alternative models that assume participants do not rely on the agent's gaze at all: a random guessing model and a center bias model. The random guessing model assumed participants randomly clicked on the screen and was implemented as sampling from a uniform distribution over all possible coordinates, $\mathcal{U}(0, 1920)$. The center bias model assumed participants always clicked near the screen center and was implemented as sampling from a Normal distribution with the screen center as the mean, and one balloon width as the variance, $\mathcal{N}(960, 160)$. Note that the center bias model also predicted imprecision should be higher for targets further out on the screen. However, compared to the gaze model, it predicted a steep effect towards the sides, resulting in a V-shaped pattern (imprecision as the distance between the target location and the screen center). All cognitive models were implemented in WebPPL [@goodman2014design].[^6]

[^6]: In an exploratory analysis, we simulated data for two more alternatives: a line-of-sight tracing model that assumed no inferential noise in the participants' gaze following ability, and a model building up on the line-of-sight tracing with added motor noise. Please note that these did not predict a U-shape pattern, since all target locations would be influenced by the motor noise equally. For further details, see Supplements.

We compared models via the marginal likelihood of the data under each model. The pairwise ratio of marginal likelihoods for two models is also known as the Bayes Factor, which quantifies the quality of a model's predictions by averaging over the possible values of the model's parameters weighted by the prior probabilities of those parameter values. It can be used to estimate how much more likely the data under one model are compared to the other. Bayes Factors implicitly consider model complexity: models with more parameters often have broader prior distributions over parameters, which might weaken potential gains in predictive accuracy.

## Results

```{r gazemodel_results}
gazemodel_comparison_kids <- readRDS("../data/gazemodel-kids-comparison-bf.rds")
gazemodel_comparison_adults <- readRDS("../data/gazemodel-adults-comparison-bf.rds")
gazemodel_corrs <- readRDS("../saves/gazemodel_correlations.rds")
gazemodel_prior <- readRDS("../saves/gazemodel_prior.rds")
```

We found very clear support for our gaze model, both in children as well as adults. A strong correlation between the data mean and the gaze model estimate ($\sigma_v$) showed that the data mean is suitable to quantify individual differences: child sample *r* = `r gazemodel_corrs$r[gazemodel_corrs$corr == "gazemodel_param_kids"]`, 95%CI [`r gazemodel_corrs$lower[gazemodel_corrs$corr == "gazemodel_param_kids"]`, `r gazemodel_corrs$upper[gazemodel_corrs$corr == "gazemodel_param_kids"]`]; adult sample *r* = `r gazemodel_corrs$r[gazemodel_corrs$corr == "gazemodel_param_adults"]`, 95%CI [`r gazemodel_corrs$lower[gazemodel_corrs$corr == "gazemodel_param_adults"]`, `r gazemodel_corrs$upper[gazemodel_corrs$corr == "gazemodel_param_adults"]`]). The gaze model predicted a U-shaped pattern which we also observed in our data (see Figure \@ref(fig:fig3)C). The model comparison strongly favored our gaze model over the center bias model (child sample $logBF_{10}$ = `r gazemodel_comparison_kids$bf_inf_center`; adult sample $logBF_{10}$ = `r gazemodel_comparison_adults$bf_inf_center`) and the random guessing model (child sample $logBF_{10}$ = `r gazemodel_comparison_kids$bf_inf_guess`; adult sample $logBF_{10}$ = `r gazemodel_comparison_adults$bf_inf_guess`). For the child sample, we went one step further into the analysis. When correlating the observed data across all target positions with the predictions of the three models, we found a high similarity for the gaze model: *r* = `r gazemodel_corrs$r[gazemodel_corrs$corr == "gazemodel_pred_kids"]`, 95%CI [`r gazemodel_corrs$lower[gazemodel_corrs$corr == "gazemodel_pred_kids"]`, `r gazemodel_corrs$upper[gazemodel_corrs$corr == "gazemodel_pred_kids"]`], while the correlations with the alternative models were smaller (center bias model: *r* = `r gazemodel_corrs$r[gazemodel_corrs$corr == "centermodel_pred_kids"]`, 95%CI [`r gazemodel_corrs$lower[gazemodel_corrs$corr == "centermodel_pred_kids"]`, `r gazemodel_corrs$upper[gazemodel_corrs$corr == "centermodel_pred_kids"]`]; random guessing model: *r* = `r gazemodel_corrs$r[gazemodel_corrs$corr == "randommodel_pred_kids"]`, 95%CI [`r gazemodel_corrs$lower[gazemodel_corrs$corr == "randommodel_pred_kids"]`, `r gazemodel_corrs$upper[gazemodel_corrs$corr == "randommodel_pred_kids"]`]). The gaze model's prior over potential target locations assumed that participants' clicks would be skewed towards the screen center. For children, we estimated the width of the prior's distribution based on the participants' age. Interestingly, we found that the differential age effects on the center bias prior were minor (intercept = `r gazemodel_prior$mode[gazemodel_prior$type == "intercept"]`, 95%HDI [`r gazemodel_prior$lci[gazemodel_prior$type == "intercept"]`; `r gazemodel_prior$uci[gazemodel_prior$type == "intercept"]`]; slope = `r gazemodel_prior$mode[gazemodel_prior$type == "slope"]`, 95%HDI [`r gazemodel_prior$lci[gazemodel_prior$type == "slope"]`; `r gazemodel_prior$uci[gazemodel_prior$type == "slope"]`]). The slope of the prior indicated that older children were only marginally less drawn towards the screen center compared to the younger children.

(ref:figlab3) **Gaze model results** (A) Developmental trajectory of the estimated model parameter. Grey dots show individual level parameter values. The black line shows the maximum a posteriori (MAP) estimate; blue lines show 1000 draws from it. The large black point with 95% HDI shows the mean of the model parameter for the adult sample. We added minimal horizontal and vertical noise to the adult individual level parameter values to avoid overplotting. (B) Correlation between estimated mode of the model parameter and data mean per individual, faceted by age group. In the child sample, color denotes age in years. Grey regression lines with 95% CI show smooth conditional means based on linear models, with *Pearson*'s correlation coefficient *r*. (C) Pattern recovery. Imprecision in target width for each target bin by age group. Model predictions in blue; data in grey. (D) Correlation between the observed data and the predictions of the three models by target position and age group (across individuals; only for the child sample).

```{r fig3, include = T, out.width = "100%", fig.align = "center", fig.cap = "(ref:figlab3)"}
knitr::include_graphics("../figures/gazemodel_plot.png")
```

## Discussion

We presented a formal cognitive model of gaze following to describe how gaze following develops with age and varies between individuals. We modeled gaze following as a process in which participants estimate pupil angles based on the pupil location within the eye. By following the resulting gaze vector, they consequently arrive at the attentional focus of the agent. Individual differences can be explained as varying levels of imprecision in the pupil angle estimation. We assume the basic process of gaze following to be the same across the lifespan, though individuals become increasingly precise with age. While we did not include an infancy sample, we believe the process of gaze following should operate similarly — if not other cues such as the object saliencies or head directions are followed instead. By conducting model comparisons, we ruled out simpler explanations of the data.

In addition, we observed differences in performance depending on gaze location: participant data showed that precision levels dropped as the agent's gaze moved further away from the center. Our gaze model predictions recovered this "signature pattern" in the data. Future research could use this signature in the data as evidence of whether diverse communities employ the same inferential mechanism to solve the task, speaking for a shared cognitive architecture.

Interestingly, the U-shaped pattern in the TANGO task can be conceptually compared to the result patterns of @michelon2006two: in their Level 1 perspective-taking task, an increased distance between the agent and the target decreased performance in adults (i.e., reaction times). Targets closer to the midline were more easily traced than ones further away from the agent. The authors concluded that visual acuity is generally higher for locations on the vertical than the diagonal axis ("oblique effect"; [@appelle1972perception; @heeley1997oblique; @mikellidou2015oblique]). Similarly, @symons2004you have found that adults' acuity for gaze direction depends on the target location. Not only is the increased imprecision for TANGO trials in which the target lands further out consistent with this finding, but our gaze model poses a viable explanation for this effect.

A limitation of our model is that we cannot disentangle how much of the participants' uncertainty comes from a noisy estimate of the agent's attentional focus and how much is due to imprecise clicking (e.g., experiencing motor issues, adding random noise to the click). However, we believe imprecise clicking to be of minor concern, since the children in our sample seemed determined in where they clicked and to not have issues with aiming or motor control (see precision in training trials in Supplements). 

A critical feature of our model is that it assumes gaze following to rely on vector following: subjects are modeled to calculate pupil angles which serve as gaze vectors to point to the attentional focus point of an agent. Even though this vector following component is a geometrical calculation, one must first interpret the agent's eyes as a relevant social stimulus. Therefore, our model describes gaze following as a particular form of vector following in a social context. 

# Study 3: Components of gaze following

Study 3 examined the components of gaze following and whether it can be fully reduced to physical vector following. The positive link between TANGO and social-environmental factors like age of childcare entry [@prein2023tango] underline how social interaction is integral to gaze following. Nevertheless, it is unclear how gaze following relates to other forms of perspective-taking [@astor2022gaze]. Therefore, we investigated associations between gaze following and other measures of social-cognitive abilities.

First, we experimentally isolated the vector following component of the TANGO. We designed a new non-social vector following task that shared all crucial design features of the TANGO. Second, we assessed children's social-cognitive abilities by administering a ToM task battery, comprising four tasks from the ToM scale by Wellman and Liu [@wellman2004scaling] and two additional perspective-taking tasks [@flavell1981development; @flavell1981younga]. We reasoned that the TANGO shares task demands with the non-social vector following task while it shares its social context with the ToM tasks. We could, therefore, imagine both an absence or presence of relationship between gaze following and ToM. As stated in our pre-registration, we further assessed whether the two perspective-taking tasks related to gaze following. Our reasoning was that similar underlying mechanisms might be needed to solve these tasks since they require participants to take into account another person's point of view.

The study design and procedure obtained ethical clearance in the same way as Study 1. The study was pre-registered prior to data collection: (<https://osf.io/xsqkt>). Data collection took place in Leipzig, Germany, between February and March 2023.

## Participants

```{r magnet_sample}
magnet_sample <- readRDS("../saves/magnet_sample.rds")
```

The sample consisted of `r magnet_sample$n_total` children (mean age = `r magnet_sample$age_mean` years, SD = `r magnet_sample$age_sd`, range = `r magnet_sample$age_min` - `r magnet_sample$age_max`, `r magnet_sample$n_females` girls). Information on individual socio-economic status was not formally recorded.

## Procedure

Children were tested in a quiet room in their kindergarten. An experimenter guided the child through the study. For maximum control of extraneous participant variables, we employed a within-subjects study design. Participants performed the tasks in this order: (1) non-social vector following task, (2) ToM task battery, (3) TANGO. We decided on a fixed order to compare participants' performance straight-forwardly with each other. To increase engagement and decrease fatigue or fuzziness, we switched between tablet tasks and tasks with personal interaction. We presented the non-social vector following task before the TANGO so that participants would not be biased to interpret the stimuli as "agent-like".

### Non-social vector following

Modeling the structure of the TANGO, we designed a non-social vector following task. This task was presented on a tablet and used the concept of magnetism. On the upper part of the screen, there was a tube with a circular window, containing a gearwheel. On the floor, there was a magnet. The magnet got switched on (with a cartoon-like sound), whereupon the gearwheel moved towards the magnet. The gearwheel moved so that its center aligned with the magnet center while staying inside the circular window. Participants were then asked to locate the magnet. Access to the magnet's true location was manipulated by a wooden wall: participants either had full, partial, or no visual access to the true magnet location. Compared to the TANGO, the circular window acted functionally similar to the agent's eyeball, while the gearwheel acted similar to the pupil. Participants were expected to estimate a vector from the center of the circular window to the gearwheel and extend this as a line toward the ground to locate the magnet. We deliberately decided against displaying an arrow: we aimed to keep the mechanistic functions of the TANGO and magnet stimuli as similar as possible. In both cases, the starting point of the vector needs to be estimated by the participant. With an arrow, we would have drastically reduced the level of uncertainty, since the arrow already displays all information (arrow tip as the "gaze" direction). Furthermore, we wanted to avoid referential or iconic stimuli.

Children received 19 trials with one full visual access trial, two partial visual access trials, and 16 test trials. The first trial of each type comprised a voice-over description of the presented events. We conducted our analysis with 15 test trials (excluding the voice-over trial). The outcome variable was imprecision, defined as the absolute distance between the magnet's x coordinate and the x coordinate of the participant's click. Magnet coordinates were randomized: The full width of the screen was divided into ten bins; each bin occurred equally often, while the same bin could occur in two consecutive trials; and exact coordinates within each bin were randomly generated.

### ToM task battery

We administered four tasks from the @wellman2004scaling ToM scale (see Supplements for further detail). We excluded three tasks: the Diverse Desires task to avoid ceiling effects; and both tasks involving emotions (Belief Emotion and Real-Apparent Emotion), as we aimed at assessing the "cold, cognitive" (vs. "emotional") aspects of social cognition. We added two perspective-taking level-2 tasks ([@flavell1981development; @flavell1981younga]; where children were asked whether a turtle appeared to be on its back or feet / a worm lay on a red or blue blanket from the experimenter's point of view) with the aim of increasing the variability we can capture between individuals, and since we hypothesized that perspective-taking would rely on similar mechanisms than gaze following, both relying on another's person egocentric frame of reference. 

### Gaze following

As in Study 1 and 2, we presented children with the TANGO [@prein2023tango]. To accentuate the social aspect of the TANGO, we exchanged the animal agents (used in the previous two studies) with human faces, which were modeled after the local population in appearance (already created for another project on cross-cultural similarities in gaze following (<https://osf.io/tdsvc>)). This further highlighted the contrast (i.e., social vs. non-social context) to the non-social vector following task.[^7]

[^7]: In an exploratory analysis, we compared children's imprecision levels in the TANGO task with animal vs. human agents. Based on a GLMM analysis, we conclude that there was no evidence of a stable effect of stimulus choice. See Supplements for further detail.

## Analysis

By design, the TANGO and the non-social vector following task involved vector following. Based on our computational model, we expected children's performance in both tasks to correlate with each other. For each task, we calculated the mean level of imprecision for each subject and correlated them using *Pearson's* correlation coefficient.

For the ToM battery, we aggregated the score of all solved tasks. Please note that the ToM score acted as an umbrella term and included the two perspective-taking tasks. Regarding the relationship between the two vector following tasks and the ToM measures, we could imagine two possible scenarios: (A) If gaze following recruited a social-cognitive ability beyond geometric vector following, we expected that ToM measures would correlate more strongly with the gaze following task than with the non-social vector following task. (B) If gaze following relied purely on task-specific geometric processes, then the correlation between gaze following and ToM measures would be comparable to the correlation between non-social vector following and the ToM measures. For the association between the aggregate ToM scores and the gaze following / non-social vector following tasks, we used *Spearman's* rank correlation coefficients.

We compared the correlation between gaze following and ToM measures and the correlation between non-social vector following and ToM measures by using the Williams' test from the function `cocor.dep.groups.overlap` (designed for two dependent overlapping correlations) from the package `cocor` [@diedenhofen2015cocor].

To estimate which components best explain the gaze following score, we conducted a model comparison with GLMMs predicting the mean imprecision in gaze following by age, imprecision in non-social vector following, the ToM aggregate score, or the aggregate of the two perspective-taking tasks (subset of ToM battery; example of model notation in `R: tango_mean ~ age_centered + magnet_scaled + perspective_scaled`). The outcome variable was modeled by a lognormal distribution. We wanted to assess whether the ToM aggregate score or the singled-out perspective-taking score added additional explanatory value when predicting the gaze following score. We hypothesized that perspective-taking seemed most closely theoretically related to gaze following as in both cases the participant was asked to judge another person's point of view. 

## Results

```{r magnet_results}
magnet_williamsttest_tom <- readRDS("../saves/magnet_williams_tom.rds")
magnet_williamsttest_perspective <- readRDS("../saves/magnet_williams_perspective.rds")
magnet_cormatrix <- readRDS("../saves/magnet_cormatrix.rds")
magnet_model <- readRDS("../saves/magnet_winningmodel.rds")
magnet_descriptives <- readRDS("../saves/magnet_descriptives.rds")
```

Children performed similarly well in the social and non-social vector following tasks (gaze following mean = `r magnet_descriptives["tango_mean",]$mean`, sd = `r magnet_descriptives["tango_mean",]$sd`, range = [`r magnet_descriptives["tango_mean",]$min` — `r magnet_descriptives["tango_mean",]$max`]; vector following mean = `r magnet_descriptives["magnet_mean",]$mean`, sd = `r magnet_descriptives["magnet_mean",]$sd`, range = [`r magnet_descriptives["magnet_mean",]$min` — `r magnet_descriptives["magnet_mean",]$max`]). The mean aggregate ToM score was `r magnet_descriptives["tom_aggregate",]$mean` (sd = `r magnet_descriptives["tom_aggregate",]$sd`, range = [`r magnet_descriptives["tom_aggregate",]$min` — `r magnet_descriptives["tom_aggregate",]$max`]), while the mean aggregate perspective-taking score was `r magnet_descriptives["perspective_aggregate",]$mean` (sd = `r magnet_descriptives["perspective_aggregate",]$sd`, range = [`r magnet_descriptives["perspective_aggregate",]$min` — `r magnet_descriptives["perspective_aggregate",]$max`]).

Gaze following substantially correlated with the non-social vector following task, *r* = `r magnet_cormatrix$r[magnet_cormatrix$Correlation == "Tango x Magnet"]`, 95%CI [`r magnet_cormatrix$lower[magnet_cormatrix$Correlation == "Tango x Magnet"]`, `r magnet_cormatrix$upper[magnet_cormatrix$Correlation == "Tango x Magnet"]`] (see Figure \@ref(fig:fig4)B). While the tasks highly overlap in task demands, their measures shared some, but not all of their variance. 

ToM abilities did not correlate with gaze following ($\rho$ = `r magnet_cormatrix$r[magnet_cormatrix$Correlation == "Tango x ToM"]`, 95%CI [`r magnet_cormatrix$lower[magnet_cormatrix$Correlation == "Tango x ToM"]`, `r magnet_cormatrix$upper[magnet_cormatrix$Correlation == "Tango x ToM"]`]) or non-social vector following ($\rho$ = `r magnet_cormatrix$r[magnet_cormatrix$Correlation == "Magnet x ToM"]`, 95%CI [`r magnet_cormatrix$lower[magnet_cormatrix$Correlation == "Magnet x ToM"]`, `r magnet_cormatrix$upper[magnet_cormatrix$Correlation == "Magnet x ToM"]`]), and the correlations did not differ from each other, Williams' test *t*(`r magnet_williamsttest_tom$parameter`) = `r round(magnet_williamsttest_tom$statistic, 2)`, *p* = `r round(magnet_williamsttest_tom$p.value, 2)`.

Interestingly, gaze following and perspective-taking correlated with each other, $\rho$ = `r magnet_cormatrix$r[magnet_cormatrix$Correlation == "Tango x Perspective-taking"]`, 95%CI [`r magnet_cormatrix$lower[magnet_cormatrix$Correlation == "Tango x Perspective-taking"]`, `r magnet_cormatrix$upper[magnet_cormatrix$Correlation == "Tango x Perspective-taking"]`]. Please note that the TANGO quantifies imprecision in gaze following. Therefore, a negative correlation suggests that imprecision in gaze following corresponds to less perspective-taking. Non-social vector following and perspective-taking did not correlate, $\rho$ = `r magnet_cormatrix$r[magnet_cormatrix$Correlation == "Magnet x Perspective-taking"]`, 95%CI [`r magnet_cormatrix$lower[magnet_cormatrix$Correlation == "Magnet x Perspective-taking"]`, `r magnet_cormatrix$upper[magnet_cormatrix$Correlation == "Magnet x Perspective-taking"]`]. However, according to the Williams' test, the two correlations did not differ significantly from each other, *t*(`r magnet_williamsttest_perspective$parameter`) = `r round(magnet_williamsttest_perspective$statistic, 2)`, *p* = `r round(magnet_williamsttest_perspective$p.value, 2)`.

Our model comparison revealed that gaze following was best predicted by a model including non-social vector following ($\beta$ = `r fixef(magnet_model)["magnet_scaled", "Estimate"]`, 95% CrI [`r fixef(magnet_model)["magnet_scaled", "Q2.5"]`; `r fixef(magnet_model)["magnet_scaled", "Q97.5"]`]) and perspective-taking ($\beta$ = `r fixef(magnet_model)["perspective_scaled", "Estimate"]`; 95% CrI [`r fixef(magnet_model)["perspective_scaled", "Q2.5"]`, `r fixef(magnet_model)["perspective_scaled", "Q97.5"]`]), even when controlling for age ($\beta$ = `r fixef(magnet_model)["age_centered", "Estimate"]`, 95% CrI [`r fixef(magnet_model)["age_centered", "Q2.5"]`, `r fixef(magnet_model)["age_centered", "Q97.5"]`]) (see Figure \@ref(fig:fig4)C and Supplements for the model comparison).

(ref:figlab4) **Components of gaze following.** (A) Study procedures. Top: TANGO (i.e., gaze following; social vector following). Bottom: Magnet (i.e., non-social vector following). The left-hand side shows screenshots of the familiarization phase; right-hand side shows screenshots of the test phase. For illustrative purposes, translucent targets are shown in the test phase. Participants cannot see them. (B) Correlations between gaze following, non-social vector following, ToM, and perspective-taking. Dots show the correlation coefficients, error bars represent 95% CIs. Please note that the ToM score acts as an umbrella term and also includes two perspective-taking tasks. (C) Influence of age, perspective-taking and non-social vector following on gaze following. The graph shows the posterior distributions for the respective predictor. Black dots represent means, thicker black lines 80% CrI, and thinner black lines 95% CrI.

```{r fig4, include = T, out.width = "100%", fig.align = "center", fig.cap = "(ref:figlab4)"}
knitr::include_graphics("../figures/magnet_plot.png")
```

## Discussion

Our gaze model assumed vector calculations on a process level. By isolating non-social vector following experimentally, we could show that gaze following does indeed, to a certain degree, rely on this component. However, non-social vector following alone did not suffice to explain variation in gaze following. Additionally, perspective-taking proved to be a relevant social-cognitive ability when predicting the performance in the TANGO. The overall ToM aggregate score did not add explanatory power.

The TANGO and the two perspective-taking tasks can be seen as instances of visuospatial perspective-taking. Often, researchers distinguish between Level 1 and Level 2 perspective-taking tasks. Level 1 perspective-taking is concerned with the visibility of objects from a particular viewpoint [@surtees2013similarities], and can usually be solved independently from another’s agent frame of reference and without mental rotation [not matching the “mentalizing criterion”; @quesque2020theoryofmind]. In contrast, Level 2 perspective-taking tasks ask participants to judge how (visually or conceptually) the world looks for another person. Solving these tasks presumably relies on a simulation of mentally transforming one's own body schema into the space of another agent [@erle2017grounded]. Participants must understand that different viewpoints lead to different perspectives [@flavell1981younga]: two agents can see the same object "in different, incompatible, fine-grained ways" [@rakoczy2022foundations]. In short, Level 1 perspective-taking addresses *what* an agent can see, while Level 2 perspective-taking addresses *how or where* they see it [@moll2006level]. The TANGO falls into the first category - however, in contrast to existing research, on a continuous scale - while the perspective-taking tasks presented within the ToM scale fall into the second category.

In the TANGO, participants locate the target by assuming that another agent perceives and looks at the it. The here-applied Level 2 perspective-taking tasks add another layer by asking how one's perspective differs from another's and how exactly the other person sees an object. @michelon2006two assessed the different processes that participants used to master Level 1 and Level 2 perspective-taking tasks and concluded that participants rely on line-of-sight tracing in the former and perspective transformation in the latter case. Line-of-sight tracing consists of locating the avatar and the target, and drawing a line between them. Note how our gaze model in Study 2 shares the underlying idea of connecting points in space via a line. Level 2 perspective-taking requires an additional step in which participants "perform a perspective transformation so that one's imagined position matches the position of the avatar" [@michelon2006two]. Therefore, the processes to solve Level 1 perspective-taking tasks might be computationally lighter since there is no need to adapt a new reference frame and there is no potential conflict between one's own and the other person's reference frame. Still, the assumed processes overlap, which could explain the correlation between the TANGO and the administered perspective-taking tasks.

@surtees2013similarities further differentiated between visual and spatial perspective-taking. While the former helps to judge if and how an agent sees an object, the latter involves judging the relative spatial locations of an agent and the object. Spatial perspective-taking does not necessitate mental states since computing a line of sight does not demand the presence of another agent [@michelon2006two] and can, therefore, be applied to non-agentive objects with a front [@surtees2013similarities]. This could explain how our participants solved the non-social vector following task.

Interestingly, we found weaker correlations between gaze following and the other ToM tasks. Similarly, in a longitudinal study, @brooks2015connecting found no direct association between gaze following at 10.5 months and explicit ToM at 4.5 years. While the ToM tasks and the TANGO shared the social context, the cognitive processes needed to solve each task might vary. As @rakoczy2022foundations reflected, perception-goal psychology (which includes gaze following) comprises understanding that others see different objects or pursue different goals. However, this ability does not necessarily entail understanding more complex meta-representational aspects; for example, understanding that mental states can be false or involve aspectual information. 

In previous work, we established that the TANGO is suited to capture meaningful variability across individuals [@prein2023tango], which is a crucial task feature when we are interested in revealing the relationship between different cognitive abilities. Importantly, the tasks we used to measure ToM abilities were not designed to capture individual differences: the aggregate score of few dichotomous items is of limited use when it comes to quantifying genuine differences between individuals. However, since these tasks are the gold standard in the social-cognitive literature [@rakoczy2022foundations; @poulin-dubois2023discontinuity; @wellman2018theory; @byom2013theory; @bialecka-pikul2021early], and measures with satisfying psychometric properties are, to the best of our knowledge, still scarce [e.g., @beaudoin2020systematic; @mayes1996testretest], we nonetheless relied on them in this study. Thus, lower correlations between ToM abilities and gaze following may reflect poor measurement characteristics on the side of ToM tasks rather than a genuine absence of association. We would like to point out that we already stated this concern in our pre-registration (<https://osf.io/xsqkt>).

If the reliability of the tasks at hand is known, one can estimate the "true" correlation between the latent constructs by applying an attenuation formula or structural equation models [@metsamuuronen2022attenuationcorrected; @trafimow2016attenuation]. Adjusting for the measurement error would increase the so-called true correlation. While we can estimate the split-half reliability for the TANGO [@prein2023tango] and the non-social vector following task, we do not have reliability estimates of the ToM measures and cannot apply said approaches. This, in turn, underlines the importance of reporting the psychometric properties of a task. The development of new measures to capture individual differences in social-cognitive abilities seems essential to move this research further.

# General discussion

In three studies, we shed light on the cognitive process underlying gaze following and its developmental trajectory across the lifespan. Study 1 focused on how gaze following changes with age. We found a steep performance improvement in the preschool years in which children became more precise in locating the attentional focus of an agent. During teenage years and early adulthood, participants reached their peak performance. Precision levels then stayed comparably stable, with a minor decay toward older adulthood. Beyond these aggregated developmental patterns, we found that individual differences exist throughout the lifespan. In Study 2, we proposed a computational cognitive model that described gaze following at a process level. We modeled gaze following as a process in which participants use the pupil location within the eyes to estimate pupil angles. To locate the attentional focus of an agent (and find a target), they extend the resulting gaze vector towards the ground. Individuals vary in their levels of uncertainty around these pupil angles. Our gaze model outperformed two alternative models, which assumed participants solved the task via a center bias or random guessing. Knowing the TANGO to be a reliable individual differences measure, we investigated potential components of gaze following in Study 3. A fundamental assumption of our computational model was that gaze following relies on a vector following process. We experimentally isolated this component by designing a non-social vector following task. Furthermore, we assessed the relationship between gaze following and traditional ToM tasks. We found that gaze following does, indeed, share a substantial part of its variance with the non-social counterpart of vector following. Additionally, perspective-taking correlated with gaze following, whereas the other ToM measures (focusing on diverse desires, knowledge access, and false beliefs) did not.

The developmental trajectory seen in Study 1 shows how abilities that emerge in infancy can continue to develop throughout childhood. While previous research established that four-month-olds can follow gaze toward one out of two objects, this is not the end point of development. By studying gaze following on a continuum, we assessed not just *whether*, but *how precisely* children locate others’ attentional focus. In previous work, we have shown that these individual differences are meaningful (e.g., connected to theoretically related constructs, and showing high split half and retest reliability; [@prein2023tango]). Capturing individual variation is crucial when we study development and the improvement in social-cognitive abilities. 

Preschool children increased their precision level to locate an agent's attentional focus, which then stayed comparably stable across adulthood. Older adults decreased slightly in their precision levels. This developmental trajectory of a first emergence with a rapid improvement, followed by a plateau and slight decline toward older age, might be representative of many cognitive processes. 

In Study 2, we proposed a theoretical framework to interpret the development and individual differences in gaze following. Our computational cognitive model assumes that participants estimate a pupil angle (i.e., the angle between a line extending vertically downwards from the pupil center and a line connecting the pupil and eye center; line-of-sight; see Figure \@ref(fig:fig2)A). The model parameter estimates a participant's latent ability to follow gaze and can explain why individuals differ in their precision to locate an agent's attentional focus. The model proposes that development in gaze following equals a reduction in noise when estimating the agent's pupil angles. We found strong evidence for the proposed gaze model when comparing it against two alternative models and correlating its predictions with the observed data (see Figure \@ref(fig:fig3)D), both for children and adults. Notably, the model recovers signature patterns in the data (see Figure \@ref(fig:fig3)C).

In Study 3, we tested the relation between gaze following and non-social vector following. As implied by our gaze model, we found that gaze following relates to the ability to estimate vectors in space. Already @butterworth1991minds have argued that, as the scene of actions, space is the commonality between different minds. The spatial vector following ability might be helpful in several social-cognitive tasks, for example, action prediction [@friesen2011gaze], and intention understanding. Predicting which object another agent likely wants to grasp or calculating their movement pathway could rely on similar vector following abilities. 

Gaze as displayed in the TANGO versus as in real-life social interactions differs with regard to which information is available. In the TANGO, the agent’s eyes are big and round, with uniform colors, white sclera, fully visible iris and pupils, and continuous eye movement. Eye gaze in natural social interactions often provides less information and is more ambiguous. Even though the TANGO and our gaze model are designed within a 2D world, we believe the mechanisms can be extrapolated into the 3D world. The processes of understanding gaze in daily life likely rely on the same principles as proposed in this paper. In Study 3, we presented the first evidence that this might be the case. We administered Level 2 perspective-taking tasks in which participants needed to adapt another person's frame of reference in a real-world social interaction. The correlation between this task and the TANGO speaks toward a unified mechanism behind these two visual perspective-taking tasks, regardless of the testing setup or stimulus features. Clearly, our real-life environment is visually more cluttered and diverse than the one presented in our tablet task. Here, however, additional informational sources are available to infer where others are looking; for example, body or head orientation or common ground [@bohn2018common; @moll2013primacy; @osborne-crowley2020social]. From a modeling perspective, a shared interaction history or diverse desires might be represented as non-uniform prior distributions over locations in the visual scenery. This way, our gaze model could be expanded to include more complex processes like mental state reasoning. 

Theories of gaze following differ in whether they illustrate why children pay attention to gaze in the first place versus how they identify the exact location of gaze. While we described  the process behind children’s increasing precision in gaze following, we still need to further explore the driving forces behind this development. Existing theories broadly vary in how much importance they place on (A) experience and social environment, and (B) social awareness vs. domain-general learning mechanisms (see categorization by @astor2022gaze). For example, it has been hypothesized that infants might be equipped with an innate gaze module and special neural mechanisms to detect eyes [@baron-cohen1995mindblindness; @batki2000there]; that children identify contingencies in social interactions and, in these, get reinforced to follow gaze [@triesch2006gaze; @corkum1998origins; @silverstein2021infants]; or that children are intrinsically socially motivated and simulate their own experiences to understand others [@tomasello1999social; @meltzoff2007me; @astor2020social; @friesen2011gaze; @ishikawa2020learning]. As seen in @prein2023tango, precision in gaze following is linked to receptive vocabulary and opportunities for social interaction (e.g., number of siblings and age when entering childcare). Which exact kind of interactions are most helpful to improve precision in gaze following remains unknown.

# Limitations

In this paper, we have focused on studying variation across ages and individuals. However, our findings rely on participants from Western, Educated, Industrialized, Rich, and Democratic (WEIRD) backgrounds [@henrich2010weirdesta]. Cultural variation has been found in many foundational aspects of cognition and socialization: for example, in parent-child interaction and communication [@nielsen2017persistent]. First evidence suggests that cultural variation in face-to-face interactions does not influence infants' gaze shifts [@hernik2019infant]. While we cannot generalize our here-reported developmental trajectory to different socio-environmental settings, we predict that our presented process-model of gaze following holds true across communities. Analyzing cross-cultural variation and checking for predicted "signature patterns" in the data will inform our modeling work and theory building in further detail [@amir2020crosscultural]. 

In Study 1, we recruited older participants online which might have selected a particular subgroup of this age range. Seventy-year-olds who have working Wi-Fi connections, know how to use a computer, and are registered on *Prolific* might not be representative of their age group. We can imagine that results from a more diverse, in-person data collection might show different developmental trajectories toward old age.

Our computational model of gaze following estimates one person-specific parameter for how accurately participants locate another person's attentional focus. The model assumes no motor imprecision in this estimation. However, younger children could have located the agent's focus at one particular point but clicked somewhere slightly off for motor control reasons. This would blur the model's estimation of the inferential component. However, in the first training trial, in which children were simply asked to touch the balloon, we found nearly perfect precision levels [cf. @prein2023tango]. Motor issues and inaccurate aiming, resulting in falsely wide estimations in the model's inferential component, seem unlikely. 

In Study 3, we matched the non-social vector following task as closely as possible to the TANGO. However, the starting positions differ: the magnet never appeared in the center of the screen. The starting point of the balloon might be especially important when interpreting the U-shaped pattern in Study 2. Furthermore, in the TANGO, two eyes are presented and information of the two (matching) cues needs to be integrated to infer the target's location. In the non-social vector following task, only one circular window with a gearwheel inside is presented as a directional cue, and there is no need to integrate two different information sources. In addition, we want to mention that the gaze presented in the TANGO might be more prominent compared to real-life social interactions (e.g., perfectly round and visible sclera; see discussion above). Future research should investigate how factors like self-propelled movement, spatial layout, and number of information sources influence the mechanisms of gaze following.

# Conclusion

In three studies, we have illuminated the lifelong development of precisely estimating another's gaze direction, and the psycho-physical process behind this. We have shown that gaze following continues to develop beyond infancy, and that individuals differ in their precision levels to localize the gaze direction of an agent. Our proposed process-level theory of gaze following modeled individual differences in precision as varying levels of uncertainty in the estimated gaze vectors. Consequently, we found that imprecision in gaze following relates to non-social vector following, as proposed by the model. Additionally, gaze following was linked to visual perspective-taking but no other aspects of ToM. The present research shows how precise and reliable measures and process models jointly inform each other and lead to a more comprehensive understanding of the psychological phenomenon in question.

\newpage

# References

```{=tex}
\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
```
::: {#refs custom-style="Bibliography"}
:::

```{=tex}
\endgroup
```